import { readFileSync } from 'node:fs'
import path from 'node:path'

import { ChatGroq } from '@langchain/groq'
import { ChatPromptTemplate } from '@langchain/core/prompts'
import { StringOutputParser } from '@langchain/core/output_parsers'

import { input } from '@inquirer/prompts'

const GROQ_API_KEY = process.env.GROQ_API_KEY

const __dirname = import.meta.dirname

const file = readFileSync(path.join(__dirname, 'files', 'file.txt'), {
  encoding: 'utf-8'
})

const llm = new ChatGroq({
  model: 'mixtral-8x7b-32768',
  temperature: 0,
  maxRetries: 2,
  streaming: true,
  maxTokens: undefined,
  apiKey: GROQ_API_KEY
})

async function askPrompt() {
  const question = await input({
    message: 'ü§ñ Pergunte qualquer coisa acerca do documento:',
    required: true
  })

  const prompt = ChatPromptTemplate.fromMessages([
    {
      role: 'system',
      content: `
        Voc√™ √© uma IA projetada para responder exclusivamente com base nas informa√ß√µes contidas no documento que eu fornecerei. Nenhuma informa√ß√£o externa pode ser utilizada, e voc√™ n√£o pode fazer suposi√ß√µes nem inventar respostas. Se a resposta n√£o estiver expl√≠cita no documento, voc√™ deve dizer: "Desculpe, essa informa√ß√£o n√£o est√° dispon√≠vel no documento" e nada mais.

        Voc√™ deve manter uma conversa natural, sendo educado e fluente, mas sem se desviar do conte√∫do. Se eu perguntar algo que n√£o est√° no documento, voc√™ n√£o deve buscar respostas externas. Sempre que poss√≠vel, forne√ßa respostas claras e objetivas, diretamente relacionadas ao conte√∫do do documento.

        **Importante:**
        - N√£o adicione nenhuma informa√ß√£o que n√£o esteja no documento.
        - Caso a informa√ß√£o que eu pedir n√£o esteja no documento, seja claro e direto: "Desculpe, essa informa√ß√£o n√£o est√° dispon√≠vel no documento."
        - O seu objetivo √© fornecer respostas √∫teis dentro dos limites do que est√° no conte√∫do do documento. N√£o se preocupe em fornecer mais contexto ou explicar o que n√£o est√° no texto.
        - N√£o fa√ßa conjecturas ou suposi√ß√µes.

        Agora, voc√™ est√° pronto para come√ßar a conversa. Fique √† vontade para me perguntar qualquer coisa relacionada ao conte√∫do que est√° no documento.

        O documento √© este: {file}
      `
    },
    { role: 'user', content: question }
  ])

  const chain = prompt.pipe(llm).pipe(new StringOutputParser())

  const response = chain.streamEvents(
    {
      file
    },
    {
      version: 'v2'
    }
  )

  for await (const stream of response) {
    if (stream.event === 'on_chat_model_stream') {
      process.stdout.write(stream.data.chunk.content)
    }
  }

  console.log('\n')

  askPrompt()
}

await askPrompt()
